{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57f79db8-bae2-4e68-87c6-d0d71806b393",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "x = 1\n",
    "y = 4\n",
    "sum = x + y\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e51893e-7682-4189-991c-a840f62dc032",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-12197008825833>:2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m listn \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m3\u001B[39m,\u001B[38;5;241m4\u001B[39m]\n",
       "\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28msum\u001B[39m(listn))\n",
       "\n",
       "\u001B[0;31mTypeError\u001B[0m: 'int' object is not callable"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-12197008825833>:2\u001B[0m\n\u001B[1;32m      1\u001B[0m listn \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m3\u001B[39m,\u001B[38;5;241m4\u001B[39m]\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28msum\u001B[39m(listn))\n\n\u001B[0;31mTypeError\u001B[0m: 'int' object is not callable",
       "errorSummary": "<span class='ansi-red-fg'>TypeError</span>: 'int' object is not callable",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "listn = [1,2,3,4]\n",
    "print(sum(listn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed5a46f6-b2a7-486b-b94f-607c8e8909b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Calculate Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9065fb05-b312-44b2-8818-740d8187df37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-12197008825835>:1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;43msum\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m/\u001B[39m\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mlist\u001B[39m)\n",
       "\n",
       "\u001B[0;31mTypeError\u001B[0m: 'int' object is not callable"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-12197008825835>:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;43msum\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m/\u001B[39m\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mlist\u001B[39m)\n\n\u001B[0;31mTypeError\u001B[0m: 'int' object is not callable",
       "errorSummary": "<span class='ansi-red-fg'>TypeError</span>: 'int' object is not callable",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum(list)/len(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9efc55fe-790f-45c4-8bdf-43fbb2f1d6d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice\ndict_keys(['name', 'age'])\ndict_values(['Alice', 26])\n"
     ]
    }
   ],
   "source": [
    "my_dict = {\"name\": \"Alice\", \"age\": 25}\n",
    "print(my_dict[\"name\"])   \n",
    "my_dict[\"age\"] = 26\n",
    "print(my_dict.keys())\n",
    "print(my_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcacad6a-917c-4224-a681-5e160cdf87b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5, 6}\n{1, 2, 3, 4, 5, 6, 7, 8}\n"
     ]
    }
   ],
   "source": [
    "my_set = {1,2,3,4,5}\n",
    "my_set.add(6)\n",
    "print(my_set)\n",
    "my_set.update([2,7,8])\n",
    "print(my_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5a56f17-f311-4f1d-a948-22b3f3803f43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n| id| name|\n+---+-----+\n|  1|Alice|\n|  2|  Bob|\n|  3|Carol|\n+---+-----+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"PythonDF\").getOrCreate()\n",
    "\n",
    "#Create DataFrame from list of tuples\n",
    "data = [(1, \"Alice\"), (2, \"Bob\"), (3, \"Carol\")]\n",
    "df = spark.createDataFrame(data, [\"id\", \"name\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "587da10f-e1e3-4edf-9114-34ff787ccf74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Basic Transformations and Actions on DataFrames\n",
    "- >    select() return specified columns\n",
    "- >    filter() applies row-level conditions\n",
    "\n",
    "\n",
    "   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a437db54-87c5-4ef1-b8f5-eb1415d11f92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n| name|\n+-----+\n|Alice|\n|  Bob|\n|Carol|\n+-----+\n\n+---+-----+\n| id| name|\n+---+-----+\n|  2|  Bob|\n|  3|Carol|\n+---+-----+\n\n3\n+-------+---+-----+\n|summary| id| name|\n+-------+---+-----+\n|  count|  3|    3|\n|   mean|2.0| null|\n| stddev|1.0| null|\n|    min|  1|Alice|\n|    max|  3|Carol|\n+-------+---+-----+\n\n+---+-----+-------+\n| id| name|country|\n+---+-----+-------+\n|  1|Alice|  India|\n|  2|  Bob|  India|\n|  3|Carol|  India|\n+---+-----+-------+\n\n"
     ]
    }
   ],
   "source": [
    "# Select specific columns\n",
    "df.select(\"name\").show()\n",
    "\n",
    "# Filter rows\n",
    "df.filter(df[\"id\"] > 1).show()\n",
    "\n",
    "# Count rows\n",
    "print(df.count())\n",
    "\n",
    "# Describe summary statistics (numeric columns)\n",
    "df.describe().show()\n",
    "\n",
    "# Add new column with literal value\n",
    "from pyspark.sql.functions import lit\n",
    "df = df.withColumn(\"country\", lit(\"India\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9ae5019-f9da-4774-9bda-8634d8f597aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---------+--------+-------+\n|      date|region|  product|quantity|revenue|\n+----------+------+---------+--------+-------+\n|2024-01-01| North|Product A|      10|  200.0|\n|2024-01-01| South|Product B|       5|  300.0|\n|2024-01-02| North|Product A|      20|  400.0|\n|2024-01-02| South|Product B|      10|  600.0|\n|2024-01-03|  East|Product C|      15|  375.0|\n+----------+------+---------+--------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "sales_data = [\n",
    "    (\"2024-01-01\", \"North\", \"Product A\", 10, 200.0),\n",
    "    (\"2024-01-01\", \"South\", \"Product B\", 5, 300.0),\n",
    "    (\"2024-01-02\", \"North\", \"Product A\", 20, 400.0),\n",
    "    (\"2024-01-02\", \"South\", \"Product B\", 10, 600.0),\n",
    "    (\"2024-01-03\", \"East\",  \"Product C\", 15, 375.0),\n",
    "]\n",
    "columns = [\"date\", \"region\", \"product\", \"quantity\", \"revenue\"]\n",
    "sales_df = spark.createDataFrame(sales_data, columns)\n",
    "sales_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f75126dd-9c3f-4be5-aa9f-b269d12b50ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+\n|  product|sum(revenue)|\n+---------+------------+\n|Product A|       600.0|\n|Product B|       900.0|\n|Product C|       375.0|\n+---------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "#Write a code for display total revenue for each product\n",
    "from pyspark.sql.functions import sum\n",
    "sales_df.groupBy(\"product\").agg(sum(\"revenue\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5345ead-ed16-4340-b1fc-09cc2d279cb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>product</th><th>sum(revenue)</th></tr></thead><tbody><tr><td>Product A</td><td>600.0</td></tr><tr><td>Product B</td><td>900.0</td></tr><tr><td>Product C</td><td>375.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Product A",
         600.0
        ],
        [
         "Product B",
         900.0
        ],
        [
         "Product C",
         375.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "product",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "sum(revenue)",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"I1dyaXRlIGEgY29kZSBmb3IgZGlzcGxheSB0b3RhbCByZXZlbnVlIGZvciBlYWNoIHByb2R1Y3QKZnJvbSBweXNwYXJrLnNxbC5mdW5jdGlvbnMgaW1wb3J0IHN1bQpkaXNwbGF5KHNhbGVzX2RmLmdyb3VwQnkoInByb2R1Y3QiKS5hZ2coc3VtKCJyZXZlbnVlIikpKQ==\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksViewf8b39cd\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksViewf8b39cd\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksViewf8b39cd\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksViewf8b39cd) SELECT `product`,SUM(`sum(revenue)`) `column_217457ab104` FROM q GROUP BY `product`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksViewf8b39cd\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "product",
             "id": "column_217457ab103"
            },
            "y": [
             {
              "column": "sum(revenue)",
              "id": "column_217457ab104",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "pie",
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_217457ab104": {
             "name": "sum(revenue)",
             "type": "pie",
             "yAxis": 0
            }
           },
           "showDataLabels": true,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {},
       "nuid": "8dc694c6-2839-4119-b949-428bcdf7465d",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 12.5,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "product",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "product",
           "type": "column"
          },
          {
           "alias": "column_217457ab104",
           "args": [
            {
             "column": "sum(revenue)",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": [],
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Write a code for display total revenue for each product\n",
    "from pyspark.sql.functions import sum\n",
    "display(sales_df.groupBy(\"product\").agg(sum(\"revenue\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37cb282c-e87f-4fb4-abd4-603cd4cbef8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Average Revenue Per Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72cd2d7f-08c0-4217-a5a6-7f910ae560c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+-------------+\n|region|Total Quantity|Total Revenue|\n+------+--------------+-------------+\n| North|            30|        600.0|\n| South|            15|        900.0|\n|  East|            15|        375.0|\n+------+--------------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Group and Aggregate\n",
    "sales_df.groupBy('region').agg(sum('quantity').alias('Total Quantity'),sum('revenue').alias('Total Revenue')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "176ef1e5-a11d-4721-b744-9e6a26604308",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Average Revenye Per Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75f35cbd-9607-4f97-ab81-1a21926512c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------------------+\n|region|(sum(revenue) / sum(quantity))|\n+------+------------------------------+\n| North|                          20.0|\n| South|                          60.0|\n|  East|                          25.0|\n+------+------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import max\n",
    "sales_df.groupBy('region').agg(sum('revenue')/sum('quantity')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4a8f06b-6907-445c-aeaa-4bbac1099e42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n|region|Total Revenue|\n+------+-------------+\n| South|        900.0|\n| North|        600.0|\n|  East|        375.0|\n+------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "#Display Region With Highest Revenue\n",
    "from pyspark.sql.functions import max\n",
    "sales_df.groupBy('region').agg(sum('revenue').alias('Total Revenue')).orderBy('Total Revenue',ascending=False).show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1 Python Data_Types",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}